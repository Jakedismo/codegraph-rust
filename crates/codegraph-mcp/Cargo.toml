[package]
name = "codegraph-mcp"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
description = "Model Context Protocol implementation for CodeGraph"

[dependencies]
tokio = { workspace = true }
tokio-tungstenite = { workspace = true }
futures = { workspace = true }
async-trait = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
serde_yaml = "0.9"
thiserror = { workspace = true }
anyhow = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true }
tracing-appender = "0.2"
uuid = { workspace = true }
chrono = { workspace = true }
url = { workspace = true }
dashmap = { workspace = true }
parking_lot = { workspace = true }
fastrand = { workspace = true }
reqwest = { workspace = true }
sha2 = { workspace = true }
toml = { workspace = true }
rmcp = { workspace = true }
schemars = { workspace = true }
once_cell = { workspace = true }
lru = { workspace = true }
atty = { workspace = true }

# CLI dependencies
clap = { workspace = true }
colored = { workspace = true }
indicatif = { workspace = true }
dirs = "5.0"
dotenv = "0.15"
nix = { version = "0.30.1", features = ["process", "signal"] }
notify = "8.2.0"
walkdir = "2.5"
regex = { workspace = true }
rayon = { workspace = true }
num_cpus = { workspace = true }

# Internal dependencies
codegraph-core = { workspace = true }
codegraph-parser = { workspace = true }
codegraph-graph = { workspace = true, features = ["surrealdb"] }
codegraph-vector = { workspace = true, optional = true, default-features = false }
codegraph-ai = { workspace = true, optional = true }  # Re-enabled for AI-powered symbol resolution
semchunk-rs = "0.1"  # Semantic chunking for long code nodes
tokenizers = "0.20"  # Qwen2.5-Coder tokenizer for accurate token counting
# codegraph-api not used directly here; avoid pulling heavy deps
## core-rag-mcp-server intentionally not linked to keep binary lean

# AutoAgents framework for agentic workflows
autoagents = { git = "https://github.com/liquidos-ai/AutoAgents", optional = true }
autoagents-derive = { git = "https://github.com/liquidos-ai/AutoAgents", optional = true }

axum = { workspace = true, optional = true }
hyper = { workspace = true, optional = true }
tower = { workspace = true, optional = true }
http-body-util = { version = "0.1", optional = true }

[dev-dependencies]
tempfile = { workspace = true }
anyhow = { workspace = true }
serial_test = "3.2"
# rmcp already available through main dependencies for testing

[[bin]]
name = "codegraph"
path = "src/bin/codegraph.rs"

[[bin]]
name = "codegraph-official"
path = "src/bin/codegraph-official.rs"

[features]
default = []
embeddings = ["dep:codegraph-vector", "codegraph-vector/lmstudio-reranker"]
embeddings-local = ["embeddings", "codegraph-vector/local-embeddings"]
embeddings-openai = ["embeddings", "codegraph-vector/openai"]
embeddings-ollama = ["embeddings", "codegraph-vector/ollama"]
embeddings-jina = ["embeddings", "codegraph-vector/jina"]
cloud = ["embeddings-jina", "codegraph-graph/surrealdb"]
server-http = ["dep:axum", "dep:hyper", "dep:tower", "dep:http-body-util"]
qwen-integration = []
ai-enhanced = ["dep:codegraph-ai", "embeddings", "autoagents-experimental", "codegraph-ai/openai-compatible"]
autoagents-experimental = ["dep:autoagents", "dep:autoagents-derive"]
