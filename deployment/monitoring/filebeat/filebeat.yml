# Filebeat configuration for CodeGraph log shipping
# Optimized for high-throughput log collection

# Filebeat inputs
filebeat.inputs:
  # Application logs from JSON format
  - type: log
    enabled: true
    paths:
      - "/app/logs/*.json"
      - "/app/logs/codegraph-api/*.json"
    fields:
      service: "codegraph-api"
      environment: "${ENVIRONMENT:production}"
    fields_under_root: true
    json:
      keys_under_root: true
      add_error_key: true
      message_key: message
    processors:
      - timestamp:
          field: timestamp
          layouts:
            - '2006-01-02T15:04:05.000Z'
            - '2006-01-02T15:04:05Z'
          test:
            - '2023-10-01T12:00:00.123Z'
    multiline:
      pattern: '^\d{4}-\d{2}-\d{2}'
      negate: true
      match: after
      max_lines: 1000
      timeout: 5s

  # Container logs (if running in Docker)
  - type: container
    enabled: true
    paths:
      - '/var/lib/docker/containers/*/*.log'
    stream: all
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"
      - decode_json_fields:
          fields: ["message"]
          process_array: false
          max_depth: 1
          target: ""
          overwrite_keys: false

  # System logs
  - type: log
    enabled: true
    paths:
      - "/var/log/syslog"
      - "/var/log/messages"
    fields:
      service: "system"
      log_type: "system"
    fields_under_root: true

  # HTTP access logs
  - type: log
    enabled: true
    paths:
      - "/app/logs/access/*.log"
    fields:
      service: "codegraph-api"
      log_type: "access"
    fields_under_root: true

  # Error logs (high priority)
  - type: log
    enabled: true
    paths:
      - "/app/logs/error/*.log"
    fields:
      service: "codegraph-api"
      log_type: "error"
      priority: "high"
    fields_under_root: true

# Filebeat modules (for common log formats)
filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: true
  reload.period: 10s

# Global processors for all inputs
processors:
  # Add hostname
  - add_host_metadata:
      when.not.contains.tags: forwarded
      
  # Add Docker metadata if available
  - add_docker_metadata: ~
  
  # Add Kubernetes metadata if running in K8s
  - add_kubernetes_metadata: ~
  
  # Drop empty lines
  - drop_event:
      when:
        equals:
          message: ""
  
  # Fingerprint for deduplication
  - fingerprint:
      fields: ["message", "service", "@timestamp"]
      target_field: "@metadata.fingerprint"
      method: "sha256"

# Output configuration
output.logstash:
  hosts: ["logstash:5044"]
  
  # Performance optimization
  worker: 4
  bulk_max_size: 2048
  flush_interval: 1s
  compression_level: 3
  
  # Load balancing
  loadbalance: true
  
  # Connection settings
  timeout: 30s
  max_retries: 3
  backoff.init: 1s
  backoff.max: 10s

# Alternative direct Elasticsearch output (commented for Logstash pipeline)
# output.elasticsearch:
#   hosts: ["elasticsearch:9200"]
#   index: "filebeat-codegraph-%{+yyyy.MM.dd}"
#   
#   # Performance settings
#   worker: 4
#   bulk_max_size: 3200
#   flush_interval: 1s
#   compression_level: 1
#   
#   # Index lifecycle
#   template.enabled: true
#   template.pattern: "filebeat-*"
#   template.settings:
#     index.number_of_shards: 2
#     index.number_of_replicas: 1

# Logging configuration
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat.log
  keepfiles: 7
  permissions: 0644
  rotateeverybytes: 10485760 # 10MB

# Monitoring and metrics
monitoring:
  enabled: true
  elasticsearch:
    hosts: ["elasticsearch:9200"]
    username: ""
    password: ""

# HTTP endpoint for metrics
http.enabled: true
http.host: "0.0.0.0"
http.port: 5066

# Registry file for tracking processed files
filebeat.registry.path: "/usr/share/filebeat/data/registry"
filebeat.registry.file_permissions: 0600
filebeat.registry.flush: 1s

# Shutdown timeout
filebeat.shutdown_timeout: 10s

# Queue configuration for high throughput
queue.mem:
  events: 8192
  flush.min_events: 512
  flush.timeout: 1s

# Path configuration
path.home: /usr/share/filebeat
path.config: /usr/share/filebeat
path.data: /usr/share/filebeat/data
path.logs: /var/log/filebeat

# Template settings
setup.template.enabled: true
setup.template.pattern: "filebeat-*"
setup.template.fields: "fields.yml"
setup.template.overwrite: false
setup.template.settings:
  index:
    number_of_shards: 2
    number_of_replicas: 1
    codec: best_compression
    refresh_interval: "5s"

# ILM (Index Lifecycle Management) settings
setup.ilm.enabled: true
setup.ilm.rollover_alias: "filebeat"
setup.ilm.pattern: "{now/d}-000001"
setup.ilm.policy: "filebeat-policy"

# Dashboards (disabled since we use custom Kibana dashboards)
setup.dashboards.enabled: false

# Security settings (disabled for development)
ssl.verification_mode: none

# Filebeat specific settings for high performance
filebeat.max_procs: 4

# Close inactive files after this period
close_inactive: 5m

# Close renamed files
close_renamed: true

# Close removed files
close_removed: true

# Close files on EOF
close_eof: false

# Scan frequency for new files
scan_frequency: 1s

# Harvester limit per input
harvester_limit: 100

# Max bytes per message (10MB)
max_bytes: 10485760

# Tail files (start from end for new files)
tail_files: false

# Exclude files patterns
exclude_files: ['\.gz$', '\.zip$', '\.tar$', '\.bak$']